# Big Data Playground

Le projet propose un **environnement de d√©veloppement** complet pour aborder les technologies Big Data, en s‚Äôappuyant sur Spark, Scala et Hadoop (HDFS). Il facilite la **prise en main** du d√©veloppement en Scala ainsi que la **mise en place** d‚Äôun cluster Hadoop et Spark, afin de **comprendre** ces concepts, de les exp√©rimenter et d‚Äôobserver leur fonctionnement concret.

üöÄ **DEMO** ‚Üí [demo video](#r√©sultat)

Rappelons rapidement les **technologies**:
- **Hadoop** : Projet open source qui fournit un ensemble de frameworks Big Data
- **HDFS** : Hadoop Distributed File System, un syst√®me de fichiers distribu√©
- **Spark** : Framework de traitement de donn√©es distribu√©es
- **Scala** : Langage de programmation
- **SBT** : Simple Build Tool, un outil de build pour Scala
- **Maven** : Outil de build pour Java

## Table des mati√®res
- [Big Data Playground](#big-data-playground)
  - [Table des mati√®res](#table-des-mati√®res)
  - [Code Scala](#code-scala)
    - [Utilisation du Toolkit Docker](#utilisation-du-toolkit-docker)
      - [Configuration](#configuration)
  - [Hadoop \& Spark](#hadoop--spark)
    - [Architecture](#architecture)
    - [Lancement manuel](#lancement-manuel)
- [Demo](#demo)
  - [D√©roulement de la d√©mo](#d√©roulement-de-la-d√©mo)
  - [R√©sultat](#r√©sultat)
  - [Commandes utiles](#commandes-utiles)
- [Refs](#refs)
- [Repos source](#repos-source)

---

## Code Scala

Dans le dossier `app`, vous trouverez le code source de l‚Äôapplication Scala.

Pour **tester le package**, vous pouvez modifier le fichier
`app/src/main/scala/demo/demoMain.scala`
puis lancer la commande :
```bash
sbt run
```
depuis le **dossier racine du projet**.

Si vous souhaitez **changer la classe d‚Äôentr√©e par d√©faut**, √©ditez le fichier `build.sbt` et modifiez la ligne suivante :
```scala
mainClass in (Compile, run) := Some("demo.demoMain")
```

---

### Utilisation du Toolkit Docker

Le projet propose un **toolkit** permettant de lancer le code Scala/Spark sans installer localement Java, Scala, SBT ni Spark.

> **Note** : Vous aurez besoin d‚Äôun compte Docker pour acc√©der au Hub Docker et, si n√©cessaire, y pousser vos images. Les identifiants sont configur√©s dans le fichier `.env` (non versionn√© par git), situ√© dans le dossier `toolkit`.

#### Configuration

1. Dans le dossier `toolkit/`, cr√©ez un fichier `.env` ressemblant √† :
   ```
    DOCKER_USER=xxxxxxxx
    DOCKER_PASS=xxxxxxxxxxxx
    JAVA_VERSION=11.0.14.1
    SBT_VERSION=1.6.2
    SCALA_VERSION=2.12.15
   ```
   - Ajustez les versions par d√©faut de Java, Scala et SBT si besoin.

2. Rendez le script `sbt.sh` ex√©cutable :
   ```bash
   chmod +x sbt.sh
   ```

---

## Hadoop & Spark

L‚Äôarchitecture du projet est bas√©e sur un cluster Hadoop et Spark, compos√© de **4 conteneurs** :
- `hadoop-namenode` : le n≈ìud ma√Ætre HDFS
- `hadoop-datanode` : le n≈ìud esclave HDFS
- `spark-master` : le n≈ìud ma√Ætre Spark
- `spark-worker` : le n≈ìud esclave Spark

Le lancement se fait via `docker-compose` en **utilisant** des images Docker officielles. Les r√©f√©rences vers ces images se trouvent dans la section [Refs](#refs).

Une configuration de base est fournie dans le dossier `hadoop_conf/`, partag√© par Hadoop et Spark.

### Architecture

![big_data_playground.drawio](docs/big_data_playbround.drawio.png)

### Lancement manuel

```bash
cd hadoop-spark
docker-compose up
```

Vous pouvez alors acc√©der aux interfaces web suivantes :

- **UI Hadoop NameNode** : http://localhost:9870
- **UI Hadoop DataNode** : http://localhost:9864 (ne fonctionne que si vous avez ajout√© `hadoop-datanode` √† `/etc/hosts`)
- **UI Spark Master** : http://localhost:8080
- **UI Spark Worker** : http://localhost:8081

> **Note** : Ajoutez `hadoop-datanode 127.0.0.1` dans votre fichier `/etc/hosts` pour acc√©der √† l‚Äôinterface web du DataNode (utile pour t√©l√©charger les fichiers depuis le DataNode).

---

# Demo

La d√©mo illustre un **exemple simple** de traitement de donn√©es avec Spark. Elle consiste √† lire un fichier CSV, √† effectuer un traitement basique et √† sauvegarder le r√©sultat au format Parquet.

Pour lancer la d√©mo, ex√©cutez le script `demo.sh` √† la racine du projet :

```bash
./demo.sh --rm  # pour supprimer les conteneurs apr√®s
```

Vous pouvez aussi afficher l‚Äôaide :

```bash
./demo.sh help
```
```bash
help() {
    echo "Usage: $0 [--rm]"
    echo "  --rm: Remove the containers after execution."
    echo "  --force-recreate: Force recreate the containers."
    exit 1
}
```

## D√©roulement de la d√©mo

Le sch√©ma ci-dessous illustre les grandes √©tapes :

```mermaid
graph TD
    A[D√©veloppement Scala<br/><em>app/src</em>] -->|lance| B[demo_sh]

    subgraph B[./demo_sh]
        
        subgraph C[./sbt_sh]
            D[Copy] --> E[build]
            E --> F[Compile]
        end
        subgraph G[docker_commands]

            H[Package Jar]--> I[Build Docker Image]
            I --> J[Containers Hadoop & Spark]
            J --> K[Copie Jar NameNode]
            K --> L[D√©p√¥t Jar DataNode]
        end

        subgraph M[job_spark]

            N[Soumission Job Spark] --> O[Ex√©cution Jar depuis HDFS]
            O --> P[R√©cup√©ration donn√©es]
            P --> Q[Calcul Spark]
            Q --> R[Sauvegarde Parquet]
        end

        S[Affichage R√©sultats]
    end
        C --> G
        G --> M
        M --> S
        
    %% Style des noeuds avec des couleurs √©volutives
    style A fill:#6FA8DC,color:#fff,stroke:#333,stroke-width:1px
    style B fill:#F5F5DC,color:#000000
    style D fill:#8A7DC5,color:#fff
    style E fill:#9675C7,color:#fff
    style F fill:#A26DCA,color:#fff
    style H fill:#3D85C6,color:#fff
    style I fill:#357DC8,color:#fff
    style J fill:#2D75CA,color:#fff
    style K fill:#2570CC,color:#fff
    style L fill:#1D6ACC,color:#fff
    style N fill:#990000,color:#fff
    style O fill:#B00000,color:#fff
    style P fill:#CC0000,color:#fff
    style Q fill:#E69138,color:#fff
    style R fill:#F6A24B,color:#fff
    style S fill:#6AA84F,color:#fff,stroke:#333,stroke-width:1px
```

## R√©sultat

![demo video](docs/demo_video_big_data_playground.webm)

## Commandes utiles
```bash
# Lancer le cluster hadoop & spark
cd hadoop-spark
docker-compose up

# Construire le JAR
cd..
source toolkit/.env
./toolkit/sbt.sh package JAVA_VERSION=$JAVA_VERSION SBT_VERSION=$SBT_VERSION SCALA_VERSION=$SCALA_VERSION

# Copier le JAR dans le conteneur hadoop-namenode
docker cp ./toolkit/target/scala-2.12/demo_recette_2.12-0.1.jar hadoop-namenode:/opt/hadoop/data/nameNode/demo_recette_2.12-0.1.jar

# Cr√©er le r√©pertoire /user/spark/jars et copier le JAR dans le conteneur spark-master
docker exec -it hadoop-namenode bash -c "hdfs dfs -mkdir -p /user/spark/jars"


# Copier le JAR dans HDFS
docker exec -it hadoop-namenode bash -c "hdfs dfs -put /opt/hadoop/data/nameNode/demo_recette_2.12-0.1.jar /user/spark/jars"

# Soumettre le job spark (ex√©cuter le JAR)
docker exec -it spark-master bash -c "spark-submit --class demo.demoMain --master spark://spark-master:7077 hdfs://hadoop-namenode:9000/user/spark/jars/demo_recette_2.12-0.1.jar"

# Afficher les r√©sultats
docker exec -it hadoop-namenode bash -c "hdfs dfs -ls -R /user/spark/demo.demoMain"

# Arr√™ter les conteneurs
cd hadoop-spark
docker-compose down -v
```

---

# Refs

- **Hadoop**
  - [bigdatafoundation/docker-hadoop](https://github.com/bigdatafoundation/docker-hadoop)
  - [Article Medium sur la configuration d‚Äôun cluster HDFS Docker](https://bytemedirk.medium.com/setting-up-an-hdfs-cluster-with-docker-compose-a-step-by-step-guide-4541cd15b168)

- **Spark**
  - [Image Docker Bitnami Spark](https://hub.docker.com/r/bitnami/spark/tags)
  - [GitHub Bitnami Spark](https://github.com/bitnami/containers/tree/main/bitnami/spark)
  - <https://github.com/tshine73/docker-spark-cluster/tree/master/>
  - <https://github.com/mvillarrealb/docker-spark-cluster/tree/master>

- **Scala et SBT**
  - [Docker SBT](https://hub.docker.com/r/sbtscala/scala-sbt)
  - [GitHub Docker SBT](https://github.com/sbt/docker-sbt)

- **Maven Repository**
  - [mvnrepository.com](https://mvnrepository.com/)

---

# Repos source

Base : https://github.com/gwendalauphan/big-data-playground.git
